{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5250ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edaf2e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ea901830d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b316a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.CenterCrop(16),\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "#torchvision.transforms.Normalize(\n",
    "#                                 (0.1307,), (0.3081,))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.CenterCrop(16),\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7bc0a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 16, 16])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11d214a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.6745, 0.9882, 0.9922, 0.9882,\n",
      "         0.9882, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.6627, 0.9882, 0.9882, 0.9922, 0.9882,\n",
      "         0.9882, 0.8941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1020, 0.9529, 0.9882, 0.9882, 0.5490, 0.3529,\n",
      "         0.8941, 0.9882, 0.4941, 0.7843, 0.0980, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1137, 0.9922, 0.9922, 0.3059, 0.0000, 0.0000,\n",
      "         0.3333, 0.9922, 1.0000, 0.9922, 0.6588, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0863, 0.9176, 0.9882, 0.3059, 0.0000, 0.0000,\n",
      "         0.3333, 0.9882, 0.9922, 0.9882, 0.6588, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.6627, 0.9882, 0.9882, 0.7255, 0.1098,\n",
      "         0.3333, 0.9882, 0.9922, 0.9137, 0.2431, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1725, 0.8941, 0.9882, 0.9922, 0.9176,\n",
      "         0.9176, 0.9882, 0.9922, 0.3765, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2980, 0.8824, 0.9961, 0.9922,\n",
      "         0.9922, 0.9922, 0.8863, 0.1490, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8941, 0.9882,\n",
      "         0.9882, 0.9882, 0.2471, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8980, 0.9882,\n",
      "         0.9882, 0.9882, 0.8745, 0.2588, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9922, 0.9882,\n",
      "         0.9882, 0.9882, 0.9922, 0.5216, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9922, 0.9961, 0.9176,\n",
      "         0.1961, 0.5922, 0.9961, 0.9922, 0.2706, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4314, 0.9882, 0.9176, 0.1098,\n",
      "         0.0000, 0.0000, 0.8941, 0.9882, 0.6588, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7725, 0.9882, 0.8824, 0.0000,\n",
      "         0.0000, 0.0000, 0.5529, 0.9882, 0.6588, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.9647, 0.9882, 0.6863, 0.0000,\n",
      "         0.0000, 0.0000, 0.7490, 0.9882, 0.6588, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.9922, 0.9922, 0.4941, 0.0275,\n",
      "         0.1137, 0.7020, 0.9961, 0.9176, 0.3922, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(example_data[1][0] * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e233f3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "011d2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63d7ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.fc1 = nn.Linear(28*28, 16)\n",
    "        self.fc1 = nn.Linear(16*16, 8)\n",
    "        #self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(8, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,16*16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a06201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "235d7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12e6125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      torch.save(network.state_dict(), './model.pth')\n",
    "      torch.save(optimizer.state_dict(), './optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85105ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c64253e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-759eb957afec>:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3197, Accuracy: 904/10000 (9%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.316402\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.288726\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.271002\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.270890\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.241107\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.219205\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.224950\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.187039\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.177169\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.061616\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.101992\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.021067\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.053981\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.062821\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.934695\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.905404\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.954275\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.795667\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.912122\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.821451\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.894769\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.691618\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.595094\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.732829\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.594630\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.526569\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.434243\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 1.502765\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.486200\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 1.320303\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.430508\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 1.291269\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.387241\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 1.167464\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.395763\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 1.121861\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 1.111260\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 1.063598\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.088200\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 1.209908\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.172199\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 1.121451\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 1.050376\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 1.089077\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.024802\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 1.037178\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 1.078324\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.976134\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.844875\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.894162\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.976820\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.836232\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.930250\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.778101\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.904200\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.822058\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.829668\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.908502\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.667449\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.876309\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.600002\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.826762\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.914515\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.661032\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.752211\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.731485\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.804018\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.867909\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.657723\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.736487\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.718624\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.666812\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.754364\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.699249\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 1.050054\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.696257\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.534034\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.552397\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.908809\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.547999\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.778293\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.537613\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.480320\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.623009\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.587837\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.611840\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.738979\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.635908\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.784909\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.631316\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.508555\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.476072\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.612361\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.473300\n",
      "\n",
      "Test set: Avg. loss: 0.5759, Accuracy: 8382/10000 (84%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.755535\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.628192\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.656180\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.569470\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.757626\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.582195\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.676682\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.601277\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.418102\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.691521\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.504206\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.500049\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.558777\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.362651\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.431551\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.544730\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.498701\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.554156\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.553860\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.661484\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.620492\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.609888\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.661127\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.542834\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.714349\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.448763\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.439202\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.646223\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.735991\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.905337\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.362223\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.625005\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.563638\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.736188\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.531776\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.401631\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.531228\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.441188\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.569780\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.573464\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.510524\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.408429\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.704284\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.430853\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.675267\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.526088\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.337403\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.570365\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.527867\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.465250\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.435859\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.553795\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.539949\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.534329\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.439184\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.538875\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.524057\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.593428\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.411977\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.480218\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.327745\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.537391\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.419355\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.620121\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.585283\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.534529\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.525697\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.565023\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.513203\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.471938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.515913\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.356001\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.530592\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.323770\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.327143\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.453198\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.542946\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.431793\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.650334\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.530144\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.349924\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.512308\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.437950\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.678314\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.617280\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.589346\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.419501\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.352941\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.458525\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.227311\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.489712\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.305735\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.435950\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.545153\n",
      "\n",
      "Test set: Avg. loss: 0.4465, Accuracy: 8710/10000 (87%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.421047\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.447941\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.432405\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.495563\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.294180\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.474681\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.475788\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.411808\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.460043\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.423510\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.366647\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.408901\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.403973\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.592552\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.413214\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.535158\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.246890\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.593864\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.547048\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.422001\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.662024\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.232157\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.467824\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.404222\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.533546\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.409874\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.475291\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.628410\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.620235\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.238831\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.285034\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.699925\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.461204\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.325582\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.292546\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.394905\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.386013\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.402173\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.441703\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.464981\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.426774\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.363873\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.548354\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.325450\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.634255\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.178595\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.337086\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.276731\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.332211\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.255249\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.519504\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.528127\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.719420\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.369179\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.460960\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.298200\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.475504\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.312293\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.556600\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.479051\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.560548\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.355033\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.391709\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.346145\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.358134\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.419707\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.520018\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.442257\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.455828\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.265158\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.539486\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.269596\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.459283\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.316102\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.185335\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.353142\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.422113\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.373585\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.219234\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.383962\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.528963\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.661417\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.646003\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.554716\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.407124\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.468593\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.558274\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.372062\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.371559\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.459652\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.477749\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.378136\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.504221\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.547088\n",
      "\n",
      "Test set: Avg. loss: 0.4103, Accuracy: 8810/10000 (88%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e41b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
